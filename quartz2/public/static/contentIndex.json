{"Competition":{"title":"Competition","links":[],"tags":[],"content":"Competition Notes §"},"Index":{"title":"Index","links":["SLAM"],"tags":[],"content":"As you must know by now, this is where we do our ‘cooking,’ feel free to look around as this is a full knowledge base on everything the PESH F1Tenth Team has ever learned. Wish us luck in the trials to come.\nMake sure you read some of our core notes like SLAM paper review"},"SLAM-by-Durrant-2006-Part--1":{"title":"SLAM by Durrant 2006 Part  1","links":["PDFs/Durrant-Whyte_Bailey_SLAM-tutorial-I.pdf","tags/slam","tags/krishna","tags/literature-review"],"tags":["slam","krishna","literature-review"],"content":"text\nSLAM by Durrant 2006 Part 1 §\nNotes on the Abstract §\nThere appear to be several reasons why this paper is a especial industry favorite as it clearly opens with the following hooks:\n\ntargets small, mobile, embedded and low power systems of the time\nand discusses implementation in a tutorial format\n\nDiscourse §\nIntroduction §\nStarting with a definition, the Simultaneous Localisation and Mapping (SLAM) problem/problem scenario (more on this later) requires and the checks the possibility of a “mobile robot” incrementally building a map of its vicinity while also determining its location in the course, when placed into an unknown and un-cached environment. It is of an intrinsic essence of said problem to have very influential solution in the field of robotics, should they be found. Needless to say, this is a fundamental problem of robotic motion.\nThe Problem §\n\nDefining variables §\nIn the image above, the color filled icons represent what the robot perceives using its sensors or LiDAR instruments, while the icons without a fill represent true vectors and landmarks. Directed triangles represent the path the robot is taking, while all forms of lines represent motion vectors fitting a curve. The indicated variable k represent the time instance at which the labeled vector is being considered. The unexplained variable i is an iterator of the the closest landmark given a kth vector.\n\nxk​​ is the state vector of the robot at time k\nuk​​ is the change vector applied at k−1 to change xk−1​​ to xk​​\nmi​​ is a offset/erorr vector from the estimated to true location of a landmark given landmark of identity i, assuming the true location is time invariant\nzi,k​ is an observation pertaining to the location of the ith landmark at time k. When referring to a set or history of such measurements, it is conventional short hand to denote them as zk​\n\nSet definitions §\n\nX0:k​={x0​,x1​,...,xk​}={X0:k−1​,xk​}→  The history of robot locations\nU0:k​={u1​,u2​,...,uk​}={U1:k−1​,uk​}→  The history of control vectors\nm is the set of all landmarks\nZ0:k​={z1​,z2​,...,zk​}={Z1:k−1​,zk​}→  The historical set of all landmark observations\n\nProbabilistic SLAM §\nThe probability distribution given time k:\nP(xk​,m∣Z0:k​,U)\nThis distribution describes the joint end density of the coplanar  measurements of landmark location and vehicle state (losing a dimension or two of vehicle state vector.) Since a vehicle control vector is improbable to be perfectly implemented in a real-world situation, and the change in measurements, a temporally recursive computations desirable.\nCitation §\nH. Durrant-Whyte and T. Bailey, “Simultaneous localization and mapping: part I,” in IEEE Robotics &amp; Automation Magazine, vol. 13, no. 2, pp. 99-110, June 2006, doi: 10.1109/MRA.2006.1638022.\nCredits §\nAuthor of this note: Krishna Ayyalasomayajula\n#paper-review#slam#krishna#literature-review"},"SLAM-by-Durrant-2006-Part-2":{"title":"SLAM by Durrant 2006 Part 2","links":["PDFs/Simultaneous_localization_and_mapping_SLAM_part_II.pdf"],"tags":[],"content":"text\nNotes on the Abstract §\nCitation §\nT. Bailey and H. Durrant-Whyte, “Simultaneous localization and mapping (SLAM): part II,” in IEEE Robotics &amp; Automation Magazine, vol. 13, no. 3, pp. 108-117, Sept. 2006, doi: 10.1109/MRA.2006.1678144."},"SLAM":{"title":"SLAM","links":["SLAM-by-Durrant-2006-Part--1","SLAM-by-Durrant-2006-Part-2","Solution-to-SLAM-by-M.W.M.G.-Dissanayake"],"tags":[],"content":"Simultaneous Localization and Mapping (SLAM) is a field of robotics and computer vision that deals with the problem of a robot or a device navigating an environment while simultaneously building a map of that environment. Here are some foundational papers on SLAM:\n\n\n“Simultaneous Localization and Map Building” by Hugh F. Durrant-Whyte and Tim Bailey (2006):\n\nThis paper provides an overview of the SLAM problem and introduces the basic concepts. It discusses both probabilistic and non-probabilistic approaches to SLAM.\n\n\n\n“A Solution to the Simultaneous Localization and Map Building (SLAM) Problem” by Michael Montemerlo, et al. (2002):\n\nThis paper presents a practical solution to the SLAM problem using Rao-Blackwellized particle filters. It discusses the application of this approach to real-world robotic systems.\n\n\n\n“FastSLAM: A Scalable Method for the Simultaneous Localization and Mapping Problem in Robotics” by Michael Montemerlo, et al. (2003):\n\nThis paper introduces FastSLAM, an efficient variant of the SLAM algorithm based on particle filters. It addresses the computational challenges associated with traditional SLAM methods.\n\n\n\n“Visual SLAM: Why filter?” by J. M. M. Montiel, J. Civera, and A. J. Davison (2006):\n\nThis paper focuses on visual SLAM and discusses the advantages of using a nonlinear optimization approach instead of the more traditional extended Kalman filter.\n\n\n\n“MonoSLAM: Real-Time Single Camera SLAM” by Andrew J. Davison (2007):\n\nThis paper presents MonoSLAM, a real-time SLAM system that uses a single camera. It employs an extended Kalman filter for estimation and demonstrates the feasibility of real-time monocular SLAM.\n\n\n\n“ORB-SLAM: a Versatile and Accurate Monocular SLAM System” by Raul Mur-Artal, J. M. M. Montiel, and Juan D. Tardos (2015):\n\nThis paper introduces ORB-SLAM, a feature-based monocular SLAM system that uses a bag of binary features for real-time operation.\n\n\n\n“LSD-SLAM: Large-Scale Direct Monocular SLAM” by Jakob Engel, et al. (2014):\n\nThis paper presents LSD-SLAM, a method that directly operates on image intensities for monocular SLAM. It achieves accurate and robust performance across a wide range of environments.\n\n\n\nThese papers should provide a solid foundation for understanding the principles and advancements in SLAM. Keep in mind that the field evolves, so it’s always good to explore more recent literature for the latest developments.\nIn this note, we will link to several exploratory notes into the papers above.\nNotes on the Abstract\nNotes on the Abstract\nNotes on the Abstract"},"Solution-to-SLAM-by-M.W.M.G.-Dissanayake":{"title":"Solution to SLAM by M.W.M.G. Dissanayake","links":["PDFs/Dissan.pdf"],"tags":[],"content":"text\nNotes on the Abstract §\nCitation §\nDissanayake, Gamini et al. “A solution to the simultaneous localization and map building (SLAM) problem.” IEEE Trans. Robotics Autom. 17 (2001): 229-241."}}